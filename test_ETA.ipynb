{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a71b2e4-43c2-4293-a27d-96bbc7cd481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ETA.eta import elite_translate_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598d69ff-e431-437b-ade5-5f0ca7d5e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = elite_translate_agents('phenaki.pdf', is_gpu = True, page_idx = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "641e06dc-7c1c-457a-be69-9327b2d41ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페나키: 오픈 도메인 텍스트 설명에서 가변 길이 비디오 생성 루벤 빌레가스트 모하마드 바베이자데트 피에터-얀 킨더맨스트 구글 브레인 구글 브레인 구글 브레인 rubville@google com mombz@google com pikinder@google _com Hernan Moraldo Han Mohammad Taghi Safar 구글 브레인 구글 브레인 hmoraldol 구글 브레인 hmoraldol 구글. com zhanghan@google. comsaf far@google.com Santiago Castro Julius Kunze * Dumitru Erhan University of Michigan University College London Google Brain sacastrolumich edu kjulius@google_com dumitrul google.com LO 추상 일련의 텍스트 프롬프트가 주어지면 사실적인 영상 합성이 가능한 모델인 페나키를 제시합니다. 계산 비용, 고품질 텍스트-비디오 데이터의 제한된 양, 가변 길이의 비디오로 인해 텍스트로부터 비디오를 생성하는 것은 특히 어렵다.이러한 문제를 해결하기 위해 비디오를 이산 토큰의 작은 표현으로 압축하는 비디오 표현 학습을 위한 새로운 모델을 소개한다. 이 토큰화기는 시간의 인과적 주의를 사용하여 가변 길이 비디오와 t0 작업할 수 있다.텍스트로부터 비디오 토큰을 생성하기 위해 우리는 미리 계산된 텍스트 토큰들에 조건을 맞춘 양방향 마스킹 변환기를 사용하고 있다_ 생성된 비디오 토큰들은 실제 비디오를 생성하기 위해 이어서 디토큰화된다_ 데이터 문제들을 해결하기 위해, 우리는 이미지 텍스트 코퍼스와 더 적은 수의 비디오 텍스트 예제에 대한 공동 훈련이 어떻게 비디오 데이터 세트에서 사용할 수 있는 것 이상의 일반화를 가져올 수 있는지 보여준다.이전의 비디오 생성 방법과 비교하여, 페나키는 오픈 도메인에서 프롬프트의 시퀀스(즉, 시간 변수 텍스트 O a story)에 따라 조건부로 된 임의의 긴 비디오를 생성할 수 있다. 우리가 아는 한, 시간 변수 프롬프트로부터 비디오를 생성하는 것을 논문으로 연구한 것은 이번이 처음이다_ 또한, 프레임 당 기준선과 비교하여, 제안된 비디오 인코더-decoder는 비디오당 더 적은 토큰을 계산하지만 더 나은 시공간 temporal 일관성을 가져온다.소개 이제 설명이 주어지면 사실적인 고해상도 영상을 생성할 수 있습니다.] 하지만 고품질 비디오 텍스트를 생성하는 것은 여전히 어렵습니다: 본질적으로, 비디오는 단지 이미지의 시퀀스일 뿐이지만, 이것이 일관성 있는 비디오를 생성하는 것이 쉽다는 것을 의미하는 것은 아니다. 실제로, 이용 가능한 고품질 데이터가 훨씬 적고 계산 요구 사항이 훨씬 더 심각하기 때문에 상당히 더 어려운 작업이다 [9L 이미지 생성의 경우, 텍스트-비디오 데이터 세트가 상당히 작은 반면, 수십억 개의 이미지-텍스트 쌍(LAION-SB 및 JFT4B 등)을 가진 데이터 세트가 있다.g_ Web Vid [~IOM 비디오가 있는 4개로, 오픈 도메인 비디오의 더 높은 복잡성을 고려할 때 충분하지 않다_ 계산의 경우, 현재 최첨단 이미지 생성 모델을 훈련하는 것은 이미 최첨단 계산 능력을 밀어 동영상, 특히 가변 길이의 비디오를 생성할 공간을 거의 내지 않고 있다.\n"
     ]
    }
   ],
   "source": [
    "print(eta.translate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492105c-6a32-492a-8480-421486871f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MISC",
   "language": "python",
   "name": "misc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
